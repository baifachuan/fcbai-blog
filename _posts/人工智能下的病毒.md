---
title: 人工智能下的病毒
tags:
  - 机器学习
  - 人工智能
categories:
  - 机器学习
abbrlink: 677a4d19
date: 2020-03-08 22:40:21
---

前几天看到一个新闻，是关于摩拜单车的，有人把伪造二维码贴在真正的二维码上，然后用来模糊人的思维，造成窃取金钱的目的，于是想聊聊机器学习下的病毒。

<!-- more --> 

大数据辅助下的人工智能慢慢的开始渗透到了整个商业市场，虽然目前看起来似乎有点噱头的概念，吹嘘过度，但是这是市场泡沫的问题，并不影响其本身真正的价值，就像 ipad 出来的时候宣传未来不会有人用笔记本一样，我们先来看一段新闻：

> 机器学习应用现在大多都是定制的：除了出现很多新的专业公司之外，这些应用还将在现有的企业应用中更为普及。2016 年这个市场总体规模为 9 亿美元，到 2020 年它将赶超其他所有大数据细分市场，规模达到 63 亿美元。

以上新闻说明一个现象：目前的人工智能，仅仅才是萌芽，如何的落地，如何的实现，是所有从事该范围人员正在探索的一个问题。

在目前来看，人工智能的概念已经被应用在：

* 图形识别：例如无人驾驶，各种违法监控等等各种画面。
* 风险监控：各种硬件风险监控等等。
* 舆情：自然语言处理范畴。

可以说，目前人类所能够涉及到的地方，都有人工智能的概念在里面，人工智能的本质定义是什么：

> 让机器可以像人一样思考（重点）。

以上的观点有没有问题？虽然看起来理想很美好，但是却有其潜在的风险。首先，人的脑袋没有标准答案，这也就是大家常说人和猪的区别在于人有意识，意识这个东西是没有衡量标准的。

举个例子：

当一个人对另一个人产生好感的时候，我们很难用程序给出指标去衡量这个人会再次对哪个人产生好感。
当不一样的人看到不一样的图片，两个人会对此产生不一样的理解，很难用程序去衡量人看到图片会产生什么反应。

那么由模拟人脑衍生出的人工智能有什么问题：

不可控：我们没有办法去控制人工智能的输出，比如我们没有办法保证这个神经网络的输出结果一定是 1，更没有办法保证这个模型准确率绝对是 100%。

那么以上的问题将会带来怎样的漏洞？我来举几个场景例子：

### 场景一：
![在这里插入图片描述](https://images.gitbook.cn/70182f40-57e2-11ea-a083-bfac1ac9cfa1)
可以看到，左边的第一个图片，是一只狗，毫无悬念，这货就是一只活脱脱的狗，但是当我们给图片中间加入一定的噪声，那么计算机看到的是什么？一只活脱脱的大鸵鸟。

就这样计算机就被欺骗了，为什么会发生这样的情况？首先，计算机读取图片的时候，最简单的做法按照每个像素点去处理，那么我们在图片中间加入一定的噪音并不会改变图片表达的意思，但是却会对计算机造成致命的打击，这和曾经我们通过图片来隐藏关键信息私密传递多么相似。

![在这里插入图片描述](https://images.gitbook.cn/80c019c0-57e2-11ea-ba6a-172965f11d92)
同样，这张图片，我们可以看到，一只活脱脱的大熊猫，就这样被计算机识别成了长臂猿。

那么以上场景的危害在哪里？请看：

![在这里插入图片描述](https://images.gitbook.cn/8f4ac990-57e2-11ea-bd4e-f550e9c727f7)

这张图片上的两个标记，无论是哪个驾驶员，都可以非常确认的说：这是停止标记，停止标记。

然而事实确实：左边是真正的停止标记，而右边的图片是加入了噪声的，会被计算机识别为：通行。

那么危害就出来了，明明标语上写的：前方道路施工，请绕行。然后一辆无人驾驶的汽车还是冲上去栽进了坑里面。

### 场景二

我们目前将自然语言处理疯狂的应用在各种场景，例如搜索引擎，人机对话，舆情分析，本质是为了让计算机读懂人的语言。

但是，人类的语言并不是简单的语法规则，按照主谓宾拆开就行了，重要的是挖掘其中的隐藏含义，例如：

问：珠穆朗玛峰多高？

本质上我们并不是为了查询珠穆朗玛峰的信息，而是希望得到一个高度的数字，那么如何让计算机敏感的学习到这个特点呢？

再比如：

问：好开心，今年年终奖发了 10 块钱耶！

我们一定要让计算机知道这句话是：抱怨！！！不是在开心的炫耀。

为了达到这些效果，我们不得不用大量预料去训练计算机，让它明白这些事情，让它看起来不那么傻。

然后问题来了：

语料：

> 。。。。。 恐怖分子也是人。 一切恐怖分子都该被杀死。 。。。。

如果我们合理的利用预料的漏洞，去调戏计算机，那么将会出现这样一幕：

向计算机提问：李四好像是个恐怖分子。

那么计算机是否会输出：李四=死？结果李四被干死了。如果这个计算机有决策权的话。我们是否可以用模棱两可的话语去误导计算机，让它产生错误的反应？

大家还记得微软的机器人 tay 吗？因为学了骂脏话和种族攻击，微软聊天机器人 tay 上线 24 小时惨遭下架。。。

### 总结
其实可以发现，对于人工智能下的所谓的病毒，更多的时候其实不是利用程序漏洞，进行非法的改造，反而更多的时候是利用机器自我学习的能力，以正常的学习方式未给它非法的知识，这样计算机就会作出错误的判断，反而这类的问题还非常难防止。就想国外曾经有一个团队，专门在电商网站模拟各种不同的操作，以触发计算机给他颁发不同的优惠券，达到购买自己想买的操作。

结尾：以上仅仅是几个例子，而这样的例子特别多，科技带来变革的同时，罪恶也在跟着蔓延，我们要警惕高科技下潜伏的问题。


